{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('./images/dataset/0_index.csv',usecols=[0,2,4,8])#图片路径、经纬长短纤、经纬氨纶、长焦图片路径（如果有）\n",
    "csv_numpy = csv.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>短焦距采样图片名</th>\n",
       "      <th>经类别/纬类别</th>\n",
       "      <th>经氨纶/纬氨纶</th>\n",
       "      <th>长焦距采样图片</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>WIN_20200630_15_18_26_Pro.jpg</td>\n",
       "      <td>s/s</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>WIN_20200630_15_18_47_Pro.jpg</td>\n",
       "      <td>s/s</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>WIN_20200630_15_19_04_Pro.jpg</td>\n",
       "      <td>s/s</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>WIN_20200630_15_19_18_Pro.jpg</td>\n",
       "      <td>s/s</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WIN_20200630_15_19_32_Pro.jpg</td>\n",
       "      <td>s/s</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>481</td>\n",
       "      <td>WIN_20200720_14_26_04_Pro.jpg</td>\n",
       "      <td>s/D</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>482</td>\n",
       "      <td>WIN_20200720_14_26_21_Pro.jpg</td>\n",
       "      <td>s/D</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>483</td>\n",
       "      <td>WIN_20200720_14_26_30_Pro.jpg</td>\n",
       "      <td>D/s</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>484</td>\n",
       "      <td>WIN_20200720_14_26_38_Pro.jpg</td>\n",
       "      <td>D/s</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485</td>\n",
       "      <td>WIN_20200720_14_26_46_Pro.jpg</td>\n",
       "      <td>D/s</td>\n",
       "      <td>0/0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          短焦距采样图片名 经类别/纬类别 经氨纶/纬氨纶 长焦距采样图片\n",
       "0    WIN_20200630_15_18_26_Pro.jpg     s/s     0/0     NaN\n",
       "1    WIN_20200630_15_18_47_Pro.jpg     s/s     0/0     NaN\n",
       "2    WIN_20200630_15_19_04_Pro.jpg     s/s     0/0     NaN\n",
       "3    WIN_20200630_15_19_18_Pro.jpg     s/s     0/0     NaN\n",
       "4    WIN_20200630_15_19_32_Pro.jpg     s/s     0/0     NaN\n",
       "..                             ...     ...     ...     ...\n",
       "481  WIN_20200720_14_26_04_Pro.jpg     s/D     0/0     NaN\n",
       "482  WIN_20200720_14_26_21_Pro.jpg     s/D     0/0     NaN\n",
       "483  WIN_20200720_14_26_30_Pro.jpg     D/s     0/0     NaN\n",
       "484  WIN_20200720_14_26_38_Pro.jpg     D/s     0/0     NaN\n",
       "485  WIN_20200720_14_26_46_Pro.jpg     D/s     0/0     NaN\n",
       "\n",
       "[486 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412\n",
      "11\n",
      "63\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#四个二级if用于将对应图片的长焦图片放入数据列表中\n",
    "#这里，如果不存在长焦路径，则为nan，nan可以理解为numpy、pandas中的None，当然在python看来和None不是一个东西，判断nan用np.isnan()\n",
    "#但np.isnan()好像不能接受一个字符串参数？会报错，而nan在python中被当做是float。\n",
    "#所以直接用isinstance。\n",
    "zz,oo,zo,oz = [],[],[],[] # z for zero, o for one\n",
    "for i in range(len(csv_numpy)):\n",
    "    if csv_numpy[i][2] == '0/0':\n",
    "        zz.append(csv_numpy[i][0])\n",
    "        #if not isinstance(csv_numpy[i][3],float):\n",
    "        #    ss.append(csv_numpy[i][3])\n",
    "    elif csv_numpy[i][2] == '1/1':\n",
    "        oo.append(csv_numpy[i][0])\n",
    "        #if not isinstance(csv_numpy[i][3],float):\n",
    "        #    DD.append(csv_numpy[i][3])\n",
    "    elif csv_numpy[i][2] == '0/1':\n",
    "        zo.append(csv_numpy[i][0])\n",
    "        #if not isinstance(csv_numpy[i][3],float):\n",
    "        #    Ds.append(csv_numpy[i][3])\n",
    "    elif csv_numpy[i][2] == '1/0':\n",
    "        oz.append(csv_numpy[i][0])\n",
    "        #if not isinstance(csv_numpy[i][3],float):\n",
    "        #    sD.append(csv_numpy[i][3])\n",
    "print(len(zz))\n",
    "print(len(oo))\n",
    "print(len(zo))\n",
    "print(len(oz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339 147\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.7\n",
    "test_ratio = 0.3\n",
    "train_set, test_set = [],[]\n",
    "#这四个for以后想想能不能优化一下\n",
    "for i in range(len(zz)):\n",
    "    temp = ['./images/dataset/' + zz[i], 0]\n",
    "    if i<int(train_ratio*len(zz)):\n",
    "        train_set.append(temp)\n",
    "    else:\n",
    "        test_set.append(temp)\n",
    "for i in range(len(oo)):\n",
    "    temp = ['./images/dataset/' + oo[i], 1]\n",
    "    if i<int(train_ratio*len(oo)):\n",
    "        train_set.append(temp)\n",
    "    else:\n",
    "        test_set.append(temp)\n",
    "for i in range(len(zo)):\n",
    "    temp = ['./images/dataset/' + zo[i], 2]\n",
    "    if i<int(train_ratio*len(zo)):\n",
    "        train_set.append(temp)\n",
    "    else:\n",
    "        test_set.append(temp)\n",
    "#这是由于oz样本为0，因此零时改为3分类，后续涉及到这点的都临时改动\n",
    "'''for i in range(len(oz)):\n",
    "    temp = ['./images/dataset/' + oz[i], 3]\n",
    "    if i<int(train_ratio*len(oz)):\n",
    "        train_set.append(temp)\n",
    "    else:\n",
    "        test_set.append(temp)'''\n",
    "print(len(train_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform = None, target_transform = None):\n",
    "        '''fh = open(txt_path, 'r')\n",
    "        imgs = [] #内部为多个tuple，每个tuple为(图片路径，label)\n",
    "        for line in fh:\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0], int(words[1])))'''\n",
    "        \n",
    "        self.imgs = imgs * 3 #将数据暴力复制3份，后面会做transforms\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = Image.open(fn).convert('RGB') \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) \n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_trainloader: 150\n",
      "num_of_testloader: 45\n"
     ]
    }
   ],
   "source": [
    "#图像的初始化操作\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#数据集加载方式设置\n",
    "train_data = MyDataset(train_set, transform=train_transforms)\n",
    "test_data = MyDataset(test_set, transform=test_transforms)\n",
    "\n",
    "#由于样本不均衡，因此做重采样\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "weights = []\n",
    "for data,target in train_set:\n",
    "    if target == 1:\n",
    "        weights.append(15) \n",
    "    elif target == 2:\n",
    "        weights.append(2)\n",
    "    else:\n",
    "        weights.append(1)\n",
    "sampler = WeightedRandomSampler(weights, num_samples=1500, replacement=True)#这里随便取了一个略小于总图片数量的batchsize的倍数\n",
    "\n",
    "#然后就是调用DataLoader和刚刚创建的数据集，来创建dataloader，这里提一句，loader的长度是有多少个batch，所以和batch_size有关\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE,num_workers=0,sampler=sampler)\n",
    "#train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False,num_workers=0)\n",
    "print('num_of_trainloader:', len(train_loader))\n",
    "print('num_of_testloader:', len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 224, 224])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0\n",
    "d = 0\n",
    "for (data,target) in train_loader:\n",
    "    t=target\n",
    "    d=data\n",
    "    break\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device, train_loader, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        x,y= data\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat= model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}'.format(epoch,loss.item()))#他这里这个loss.item()是for循环里单最后一次的loss，本身就有问题。\n",
    "    \n",
    "def test(model, device, test_loader, max_acc):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):          \n",
    "            x,y= data\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            test_loss += criterion(y_hat, y).item() # sum up batch loss\n",
    "            pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = 100. * correct / len(test_data)\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        torch.save({'model': model}, 'checkpoint.pth.tar')\n",
    "        print('model saved : acc = %.4f' % acc)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_data),\n",
    "        acc))\n",
    "    return max_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18 = models.resnet18(pretrained=True)\n",
    "#alexnet = models.alexnet(pretrained=True)\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "model_conv = models.resnet18(pretrained=True)\n",
    "\n",
    "param_num = 0\n",
    "for i,param in enumerate(model_conv.parameters()):\n",
    "    param_num += 1\n",
    "for i,param in enumerate(model_conv.parameters()):\n",
    "    if i >= (param_num-2):#解冻最后2层\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "model_conv = model_conv.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_conv.fc.parameters()}\n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 1.047469\n",
      "model saved : acc = 76.1905\n",
      "\n",
      "Test set: Average loss: 0.0659, Accuracy: 336/441 (76%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.759178\n",
      "model saved : acc = 79.5918\n",
      "\n",
      "Test set: Average loss: 0.0569, Accuracy: 351/441 (80%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.443241\n",
      "\n",
      "Test set: Average loss: 0.0640, Accuracy: 315/441 (71%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.928196\n",
      "\n",
      "Test set: Average loss: 0.0644, Accuracy: 324/441 (73%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.580084\n",
      "\n",
      "Test set: Average loss: 0.0553, Accuracy: 336/441 (76%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 0.341030\n",
      "model saved : acc = 82.9932\n",
      "\n",
      "Test set: Average loss: 0.0494, Accuracy: 366/441 (83%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 0.644794\n",
      "\n",
      "Test set: Average loss: 0.0600, Accuracy: 318/441 (72%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 0.494813\n",
      "\n",
      "Test set: Average loss: 0.0544, Accuracy: 333/441 (76%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 1.215258\n",
      "model saved : acc = 84.3537\n",
      "\n",
      "Test set: Average loss: 0.0464, Accuracy: 372/441 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#UserWarning: Couldn't retrieve source code for container of type Network. 如果出现这个警告，再运行一次，第二次就没事了，注意不要重启内核\n",
    "max_acc = 0\n",
    "for epoch in range(1, 10):\n",
    "    train(model=model_conv, device=DEVICE, train_loader=train_loader,epoch=epoch)\n",
    "    max_acc = test(model=model_conv, device=DEVICE, test_loader=test_loader, max_acc = max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/yyh/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:03<00:00, 27.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_conv = models.resnet34(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_conv.fc.parameters()}\n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 0.501376\n",
      "\n",
      "Test set: Average loss: 0.0613, Accuracy: 42/69 (61%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.513787\n",
      "\n",
      "Test set: Average loss: 0.0647, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.391931\n",
      "\n",
      "Test set: Average loss: 0.0623, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.351778\n",
      "\n",
      "Test set: Average loss: 0.0582, Accuracy: 42/69 (61%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.543261\n",
      "\n",
      "Test set: Average loss: 0.0929, Accuracy: 42/69 (61%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 0.405109\n",
      "\n",
      "Test set: Average loss: 0.0524, Accuracy: 45/69 (65%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 0.558961\n",
      "\n",
      "Test set: Average loss: 0.0527, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 0.287587\n",
      "\n",
      "Test set: Average loss: 0.0511, Accuracy: 51/69 (74%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.311003\n",
      "\n",
      "Test set: Average loss: 0.0507, Accuracy: 51/69 (74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(model=model_conv, device=DEVICE, train_loader=train_loader,epoch=epoch)\n",
    "    test(model=model_conv, device=DEVICE, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#resnet18 = models.resnet18(pretrained=True)\n",
    "#alexnet = models.alexnet(pretrained=True)\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "model_conv = models.vgg16(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "#model_conv.classifier[0] = nn.Linear(25088, 4096)\n",
    "num_second_last = model_conv.classifier[3].in_features\n",
    "model_conv.classifier[3] = nn.Linear(num_second_last, num_second_last)\n",
    "num_last = model_conv.classifier[6].in_features\n",
    "model_conv.classifier[6] = nn.Linear(num_last, 2)\n",
    "\n",
    "model_conv = model_conv.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_conv.classifier[3].parameters()},\n",
    "    {'params':model_conv.classifier[6].parameters()}\n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 0.039234\n",
      "\n",
      "Test set: Average loss: 0.2682, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.014214\n",
      "\n",
      "Test set: Average loss: 0.2211, Accuracy: 45/69 (65%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.005668\n",
      "\n",
      "Test set: Average loss: 0.2541, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.008691\n",
      "\n",
      "Test set: Average loss: 0.2853, Accuracy: 42/69 (61%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.132321\n",
      "\n",
      "Test set: Average loss: 0.3135, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 2.570711\n",
      "\n",
      "Test set: Average loss: 0.3454, Accuracy: 51/69 (74%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 3.714458\n",
      "\n",
      "Test set: Average loss: 0.3400, Accuracy: 45/69 (65%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 1.539180\n",
      "\n",
      "Test set: Average loss: 0.4139, Accuracy: 45/69 (65%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.571291\n",
      "\n",
      "Test set: Average loss: 0.2755, Accuracy: 42/69 (61%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(model=model_conv, device=DEVICE, train_loader=train_loader,epoch=epoch)\n",
    "    test(model=model_conv, device=DEVICE, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18 = models.resnet18(pretrained=True)\n",
    "#alexnet = models.alexnet(pretrained=True)\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "model_conv = models.alexnet(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.classifier[6].in_features\n",
    "model_conv.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_conv.classifier[6].parameters()}\n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(model=model_conv, device=DEVICE, train_loader=train_loader,epoch=epoch)\n",
    "    test(model=model_conv, device=DEVICE, test_loader=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
