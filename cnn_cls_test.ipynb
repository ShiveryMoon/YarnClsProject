{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('./images/dataset/0_index.csv',usecols=[0,2,4,8])#图片路径、经纬长短纤、经纬氨纶、长焦图片路径（如果有）\n",
    "csv_numpy = csv.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['WIN_20200630_15_18_26_Pro.jpg', 's/s', '0/0', nan],\n",
       "       ['WIN_20200630_15_18_47_Pro.jpg', 's/s', '0/0', nan],\n",
       "       ['WIN_20200630_15_19_04_Pro.jpg', 's/s', '0/0', nan],\n",
       "       ...,\n",
       "       ['WIN_20200720_14_26_30_Pro.jpg', 'D/s', '0/0', nan],\n",
       "       ['WIN_20200720_14_26_38_Pro.jpg', 'D/s', '0/0', nan],\n",
       "       ['WIN_20200720_14_26_46_Pro.jpg', 'D/s', '0/0', nan]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n",
      "188\n",
      "41\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "#四个二级if用于将对应图片的长焦图片放入数据列表中\n",
    "#这里，如果不存在长焦路径，则为nan，nan可以理解为numpy、pandas中的None，当然在python看来和None不是一个东西，判断nan用np.isnan()\n",
    "#但np.isnan()好像不能接受一个字符串参数？会报错，而nan在python中被当做是float。\n",
    "#所以直接用isinstance。\n",
    "ss,DD,sD,Ds = [],[],[],[]\n",
    "for i in range(len(csv_numpy)):\n",
    "    if csv_numpy[i][1] == 's/s':\n",
    "        ss.append(csv_numpy[i][0])\n",
    "        #if not isinstance(csv_numpy[i][3],float):\n",
    "        #    ss.append(csv_numpy[i][3])\n",
    "    elif csv_numpy[i][1] == 'D/D':\n",
    "        DD.append(csv_numpy[i][0])\n",
    "        #if not isinstance(csv_numpy[i][3],float):\n",
    "        #    DD.append(csv_numpy[i][3])\n",
    "    elif csv_numpy[i][1] == 'D/s':\n",
    "        Ds.append(csv_numpy[i][0])\n",
    "        #if not isinstance(csv_numpy[i][3],float):\n",
    "        #    Ds.append(csv_numpy[i][3])\n",
    "    elif csv_numpy[i][1] == 's/D':\n",
    "        sD.append(csv_numpy[i][0])\n",
    "        #if not isinstance(csv_numpy[i][3],float):\n",
    "        #    sD.append(csv_numpy[i][3])\n",
    "print(len(ss))\n",
    "print(len(DD))\n",
    "print(len(Ds))\n",
    "print(len(sD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 148\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.7\n",
    "test_ratio = 0.3\n",
    "train_set, test_set = [],[]\n",
    "#这四个for以后想想能不能优化一下\n",
    "for i in range(len(ss)):\n",
    "    temp = ['./images/dataset/' + ss[i], 0]\n",
    "    if i<int(train_ratio*len(ss)):\n",
    "        train_set.append(temp)\n",
    "    else:\n",
    "        test_set.append(temp)\n",
    "for i in range(len(DD)):\n",
    "    temp = ['./images/dataset/' + DD[i], 1]\n",
    "    if i<int(train_ratio*len(DD)):\n",
    "        train_set.append(temp)\n",
    "    else:\n",
    "        test_set.append(temp)\n",
    "for i in range(len(Ds)):\n",
    "    temp = ['./images/dataset/' + Ds[i], 2]\n",
    "    if i<int(train_ratio*len(Ds)):\n",
    "        train_set.append(temp)\n",
    "    else:\n",
    "        test_set.append(temp)\n",
    "for i in range(len(sD)):\n",
    "    temp = ['./images/dataset/' + sD[i], 3]\n",
    "    if i<int(train_ratio*len(sD)):\n",
    "        train_set.append(temp)\n",
    "    else:\n",
    "        test_set.append(temp)\n",
    "print(len(train_set),len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, imgs, transform = None, target_transform = None):\n",
    "        '''fh = open(txt_path, 'r')\n",
    "        imgs = [] #内部为多个tuple，每个tuple为(图片路径，label)\n",
    "        for line in fh:\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0], int(words[1])))'''\n",
    "        \n",
    "        self.imgs = imgs * 3 #将数据暴力复制3份，后面会做transforms\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = Image.open(fn).convert('RGB') \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) \n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_trainloader: 170\n",
      "num_of_testloader: 45\n"
     ]
    }
   ],
   "source": [
    "#图像的初始化操作\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "#数据集加载方式设置\n",
    "train_data = MyDataset(train_set, transform=train_transforms)\n",
    "test_data = MyDataset(test_set, transform=test_transforms)\n",
    "\n",
    "#由于样本不均衡，因此做重采样\n",
    "from torch.utils.data.sampler import  WeightedRandomSampler\n",
    "weights = []\n",
    "for data,target in train_set:\n",
    "    if target in (2,3):\n",
    "        weights.append(4) #长短和短长的权重翻n倍\n",
    "    else:\n",
    "        weights.append(1)\n",
    "sampler = WeightedRandomSampler(weights, num_samples=1700, replacement=True)#这里随便取了一个略小于总图片数量的batchsize的倍数\n",
    "\n",
    "#然后就是调用DataLoader和刚刚创建的数据集，来创建dataloader，这里提一句，loader的长度是有多少个batch，所以和batch_size有关\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE,num_workers=0,sampler=sampler)\n",
    "#train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE,shuffle=True,num_workers=0)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False,num_workers=0)\n",
    "print('num_of_trainloader:', len(train_loader))\n",
    "print('num_of_testloader:', len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 224, 224])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0\n",
    "d = 0\n",
    "for (data,target) in train_loader:\n",
    "    t=target\n",
    "    d=data\n",
    "    break\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,device, train_loader, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        x,y= data\n",
    "        x=x.to(device)\n",
    "        y=y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_hat= model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print ('Train Epoch: {}\\t Loss: {:.6f}'.format(epoch,loss.item()))\n",
    "    \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_loader):          \n",
    "            x,y= data\n",
    "            x=x.to(device)\n",
    "            y=y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            test_loss += criterion(y_hat, y).item() # sum up batch loss\n",
    "            pred = y_hat.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_data),\n",
    "        100. * correct / len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18 = models.resnet18(pretrained=True)\n",
    "#alexnet = models.alexnet(pretrained=True)\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "model_conv = models.alexnet(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.classifier[6].in_features\n",
    "model_conv.classifier[6] = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_conv.classifier[6].parameters()}\n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 0.323903\n",
      "\n",
      "Test set: Average loss: 0.0535, Accuracy: 51/69 (74%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.146808\n",
      "\n",
      "Test set: Average loss: 0.0454, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.356405\n",
      "\n",
      "Test set: Average loss: 0.0548, Accuracy: 54/69 (78%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.483915\n",
      "\n",
      "Test set: Average loss: 0.0608, Accuracy: 54/69 (78%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.314868\n",
      "\n",
      "Test set: Average loss: 0.0416, Accuracy: 57/69 (83%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 0.333603\n",
      "\n",
      "Test set: Average loss: 0.0702, Accuracy: 51/69 (74%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 0.089547\n",
      "\n",
      "Test set: Average loss: 0.0471, Accuracy: 54/69 (78%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 0.216139\n",
      "\n",
      "Test set: Average loss: 0.0916, Accuracy: 51/69 (74%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.609754\n",
      "\n",
      "Test set: Average loss: 0.0583, Accuracy: 54/69 (78%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(model=model_conv, device=DEVICE, train_loader=train_loader,epoch=epoch)\n",
    "    test(model=model_conv, device=DEVICE, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet18 = models.resnet18(pretrained=True)\n",
    "#alexnet = models.alexnet(pretrained=True)\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "model_conv = models.resnet18(pretrained=True)\n",
    "\n",
    "param_num = 0\n",
    "for i,param in enumerate(model_conv.parameters()):\n",
    "    param_num += 1\n",
    "for i,param in enumerate(model_conv.parameters()):\n",
    "    if i >= (param_num-2):#解冻最后2层\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "model_conv = model_conv.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_conv.fc.parameters()}\n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 1.224071\n",
      "\n",
      "Test set: Average loss: 0.0758, Accuracy: 498/690 (72%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.809651\n",
      "\n",
      "Test set: Average loss: 0.0882, Accuracy: 417/690 (60%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.573209\n",
      "\n",
      "Test set: Average loss: 0.0743, Accuracy: 489/690 (71%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.635795\n",
      "\n",
      "Test set: Average loss: 0.0782, Accuracy: 465/690 (67%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 20):\n",
    "    train(model=model_conv, device=DEVICE, train_loader=train_loader,epoch=epoch)\n",
    "    test(model=model_conv, device=DEVICE, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/yyh/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:03<00:00, 27.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "model_conv = models.resnet34(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_conv.fc.parameters()}\n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 0.501376\n",
      "\n",
      "Test set: Average loss: 0.0613, Accuracy: 42/69 (61%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.513787\n",
      "\n",
      "Test set: Average loss: 0.0647, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.391931\n",
      "\n",
      "Test set: Average loss: 0.0623, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.351778\n",
      "\n",
      "Test set: Average loss: 0.0582, Accuracy: 42/69 (61%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.543261\n",
      "\n",
      "Test set: Average loss: 0.0929, Accuracy: 42/69 (61%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 0.405109\n",
      "\n",
      "Test set: Average loss: 0.0524, Accuracy: 45/69 (65%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 0.558961\n",
      "\n",
      "Test set: Average loss: 0.0527, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 0.287587\n",
      "\n",
      "Test set: Average loss: 0.0511, Accuracy: 51/69 (74%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.311003\n",
      "\n",
      "Test set: Average loss: 0.0507, Accuracy: 51/69 (74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(model=model_conv, device=DEVICE, train_loader=train_loader,epoch=epoch)\n",
    "    test(model=model_conv, device=DEVICE, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#resnet18 = models.resnet18(pretrained=True)\n",
    "#alexnet = models.alexnet(pretrained=True)\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "model_conv = models.vgg16(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "#model_conv.classifier[0] = nn.Linear(25088, 4096)\n",
    "num_second_last = model_conv.classifier[3].in_features\n",
    "model_conv.classifier[3] = nn.Linear(num_second_last, num_second_last)\n",
    "num_last = model_conv.classifier[6].in_features\n",
    "model_conv.classifier[6] = nn.Linear(num_last, 2)\n",
    "\n",
    "model_conv = model_conv.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params':model_conv.classifier[3].parameters()},\n",
    "    {'params':model_conv.classifier[6].parameters()}\n",
    "], lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1\t Loss: 0.039234\n",
      "\n",
      "Test set: Average loss: 0.2682, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 2\t Loss: 0.014214\n",
      "\n",
      "Test set: Average loss: 0.2211, Accuracy: 45/69 (65%)\n",
      "\n",
      "Train Epoch: 3\t Loss: 0.005668\n",
      "\n",
      "Test set: Average loss: 0.2541, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 4\t Loss: 0.008691\n",
      "\n",
      "Test set: Average loss: 0.2853, Accuracy: 42/69 (61%)\n",
      "\n",
      "Train Epoch: 5\t Loss: 0.132321\n",
      "\n",
      "Test set: Average loss: 0.3135, Accuracy: 48/69 (70%)\n",
      "\n",
      "Train Epoch: 6\t Loss: 2.570711\n",
      "\n",
      "Test set: Average loss: 0.3454, Accuracy: 51/69 (74%)\n",
      "\n",
      "Train Epoch: 7\t Loss: 3.714458\n",
      "\n",
      "Test set: Average loss: 0.3400, Accuracy: 45/69 (65%)\n",
      "\n",
      "Train Epoch: 8\t Loss: 1.539180\n",
      "\n",
      "Test set: Average loss: 0.4139, Accuracy: 45/69 (65%)\n",
      "\n",
      "Train Epoch: 9\t Loss: 0.571291\n",
      "\n",
      "Test set: Average loss: 0.2755, Accuracy: 42/69 (61%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train(model=model_conv, device=DEVICE, train_loader=train_loader,epoch=epoch)\n",
    "    test(model=model_conv, device=DEVICE, test_loader=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
